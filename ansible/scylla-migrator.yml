---

- name: Install spark on scylla-migrator servers
  hosts: spark
  vars:
    home_dir: /home/ubuntu
    spark_home: /opt/spark
  tasks: 
    - name: add universe repository
      become: true
      shell: sudo add-apt-repository universe -y

    - name: Update apt-cache
      become: true
      apt:
        update_cache: yes

    - name: Install package dependencies.
      become: true
      package: name={{ item }} state=present
      with_items:
        - openjdk-8-jre
        - openjdk-8-jdk
        - unzip
        - python3-pip

    - name: install cqlsh
      ansible.builtin.pip:
        name: scylla-cqlsh
        state: present

    - name: Check that awscliv2.zip exists
      stat:
        path: awscliv2.zip
      register: stat_result

    - name: Download the awscli bundle.
      get_url: 
        url: https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip
        dest: "{{ home_dir }}/awscliv2.zip"
      when: not stat_result.stat.exists
      register: aws_cli_download_bundle

    - name: Unarchive the installer.
      unarchive: 
        src: awscliv2.zip
        dest: "{{ home_dir }}"
        remote_src: yes
        
      when: aws_cli_download_bundle.changed
      register: aws_cli_unarchive_installer

    - name: install awscli v2
      become: true
      shell: "sudo {{ home_dir }}/aws/install --update"

    - name: Delete aws zip file
      ansible.builtin.file:
        state: absent
        path: "{{ home_dir }}/awscliv2.zip"

    - name: Delete aws install directory
      ansible.builtin.file:
        state: absent
        path: "{{ home_dir }}/aws"

    - name: Download sbt
      ansible.builtin.get_url:
        url: https://github.com/coursier/coursier/releases/latest/download/cs-x86_64-pc-linux.gz
        dest: "{{ home_dir }}"

    - name: unarchive sbt
      shell: gzip -d cs-x86_64-pc-linux.gz

    - name: Delete /tmp/cs-x86_64-pc-linux.gz
      ansible.builtin.file:
        state: absent
        path: "{{ home_dir }}/cs-x86_64-pc-linux.gz"

    - name: rename cs-x86_64-pc-linux to cs
      become: yes
      shell: mv cs-x86_64-pc-linux cs
  
    - name: Change permission on sbt
      file:
        path: cs
        state: file
        mode: 0755

    - name: setup sbt
      shell: "{{ home_dir }}/cs setup -y"

    - name: Download spark
      get_url: 
        url: https://archive.apache.org/dist/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz 
        dest: "{{ home_dir }}/spark-2.4.8-bin-hadoop2.7.tgz"

    - name: Extract spark
      ansible.builtin.unarchive:
        src: "spark-2.4.8-bin-hadoop2.7.tgz"
        dest: "{{ home_dir }}"
        remote_src: yes

    - name: Empty spark home
      become: true
      ansible.builtin.file:
        state: absent
        path: "{{ spark_home }}"

    - name: Move spark to opt/spark
      become: true
      command: "sudo mv spark-2.4.8-bin-hadoop2.7 {{ spark_home }}"

    - name: Set JAVA_HOME
      ansible.builtin.lineinfile:
        path: "{{ home_dir }}/.profile"
        regexp: '^JAVA_HOME='
        line: export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

    - name: Add JAVA_HOME to PATH
      ansible.builtin.lineinfile:
        path: "{{ home_dir }}/.profile"
        regexp: '^:$JAVA_HOME'
        line: export PATH=$PATH:$JAVA_HOME

    - name: Set SPARK_HOME
      ansible.builtin.lineinfile:
        path: "{{ home_dir }}/.profile"
        regexp: '^:SPARK_HOME'
        line: "export SPARK_HOME={{ spark_home }}"

    - name: Add SPARK_HOME/bin to path
      ansible.builtin.lineinfile:
        path: "{{ home_dir }}/.profile"
        regexp: '^:$SPARK_HOME/bin'
        line: export PATH=$PATH:$SPARK_HOME/bin

    - name: Add SPARK_HOME/sbin to path
      ansible.builtin.lineinfile:
        path: "{{ home_dir }}/.profile"
        regexp: '^:$SPARK_HOME/sbin'
        line: export PATH=$PATH:$SPARK_HOME/sbin

    - name: Generate an OpenSSH keypair with the default values (4096 bits, rsa)
      community.crypto.openssh_keypair:
        path: "{{ home_dir }}/.ssh/id_ssh_rsa"
        state: present
      register: rsa_key

    - name: Allow passwordless SSH between all hosts
      lineinfile:
        dest: "{{ home_dir }}/.ssh/authorized_keys"
        state: present
        line:  "{{ hostvars[item].rsa_key.public_key }} {{ hostvars[item].ansible_host }}"
      with_items: "{{ groups['spark'] }}"

    - name: Make sure slaves file exists
      become: true
      ansible.builtin.file:
        state: touch
        path: "{{ spark_home }}/conf/slaves"

    - name: Add spark nodes to slaves file
      lineinfile:
        dest: "{{ spark_home }}/conf/slaves"
        state: present
        line:  "{{ hostvars[item].ansible_host }}"
      with_items: "{{ groups['spark'] }}"

    - name: copy worker start/stop convenience scripts
      copy:
        src: "{{ item }}"
        dest: "{{ home_dir }}"
        mode: 0755
      when: inventory_hostname in groups['worker']
      with_items:
        - start-slave.sh
        - stop-slave.sh

    - name: copy template
      template:
        src: spark-env-worker-sample
        dest: "{{ home_dir }}"
      when: inventory_hostname in groups['worker']

    - name: rename spark-env
      shell: mv spark-env-worker-sample spark-env
      when: inventory_hostname in groups['worker']

- name: Install scylla migrator on master
  hosts: spark_master
  vars:
    home_dir: /home/ubuntu
    spark_home: /opt/spark
  environment:
    JAVA_HOME: /usr/lib/jvm/java-8-openjdk-amd64
    SPARK_HOME: /opt/spark
    PATH: "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/ubuntu/.local/share/coursier/bin:/usr/lib/jvm/java-8-openjdk-amd64:/opt/spark/bin:/opt/spark/sbin"

  tasks:
    - name: Clone scylla-migrator repo
      ansible.builtin.git:
        repo: https://github.com/scylladb/scylla-migrator.git
        dest: "{{ home_dir }}/scylla-migrator"

    - name: copy master start/stop convenience scripts
      copy:
        src: "{{ item }}"
        dest: "{{ home_dir }}/scylla-migrator"
        mode: 0755
      with_items:
        - start-spark.sh
        - stop-spark.sh
        - start-slave.sh
        - stop-slave.sh
        - config.dynamodb.yml
    
    - name: copy template
      template:
        src: "{{ item }}"
        dest: "{{ home_dir }}/scylla-migrator"
        mode: 0755
      with_items:
        - spark-env-master-sample
        - submit-alternator-job.sh
        - submit-cql-job.sh
        - submit-cql-job-validator.sh

    - name: rename spark-env
      shell: cd "{{ home_dir }}/scylla-migrator" && mv spark-env-master-sample spark-env

    - name: change file permissions - spark-env and config.dynamodb.yml
      ansible.builtin.file:
        mode: 0655
        state: file
        path: "{{ home_dir }}/scylla-migrator/{{ item }}"
      with_items:
        - spark-env
        - config.dynamodb.yml

    - name: build scylla-migrator
      shell: "./build.sh"
      register: build
      args:
        chdir: "{{ home_dir }}/scylla-migrator"

    - debug: msg="{{ build.stdout }}"

    - debug: msg="{{ build.stderr }}"
...